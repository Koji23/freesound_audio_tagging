{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to True for full dataset and learning\n",
    "COMPLETE_RUN = True\n",
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "# import IPython\n",
    "import wave\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/train_noisy.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path + \"/train_noisy.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + \"/train_noisy.csv\")\n",
    "test = pd.read_csv(data_path + \"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19604</th>\n",
       "      <td>fcfcbd51.wav</td>\n",
       "      <td>Child_speech_and_kid_speaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6930</th>\n",
       "      <td>592b3420.wav</td>\n",
       "      <td>Buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>20cf9968.wav</td>\n",
       "      <td>Shatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15661</th>\n",
       "      <td>ca27d86b.wav</td>\n",
       "      <td>Stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>4a8f7729.wav</td>\n",
       "      <td>Trickle_and_dribble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname                         labels\n",
       "19604  fcfcbd51.wav  Child_speech_and_kid_speaking\n",
       "6930   592b3420.wav                           Buzz\n",
       "2531   20cf9968.wav                        Shatter\n",
       "15661  ca27d86b.wav                         Stream\n",
       "5806   4a8f7729.wav            Trickle_and_dribble"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>23244f49.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>06604d51.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1a5c4e84.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2d15ca77.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>20e285c7.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
       "581  23244f49.wav                                   0          0   \n",
       "114  06604d51.wav                                   0          0   \n",
       "438  1a5c4e84.wav                                   0          0   \n",
       "732  2d15ca77.wav                                   0          0   \n",
       "540  20e285c7.wav                                   0          0   \n",
       "\n",
       "     Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
       "581                0         0     0          0            0   \n",
       "114                0         0     0          0            0   \n",
       "438                0         0     0          0            0   \n",
       "732                0         0     0          0            0   \n",
       "540                0         0     0          0            0   \n",
       "\n",
       "     Bathtub_(filling_or_washing)  Bicycle_bell        ...          \\\n",
       "581                             0             0        ...           \n",
       "114                             0             0        ...           \n",
       "438                             0             0        ...           \n",
       "732                             0             0        ...           \n",
       "540                             0             0        ...           \n",
       "\n",
       "     Toilet_flush  Traffic_noise_and_roadway_noise  Trickle_and_dribble  \\\n",
       "581             0                                0                    0   \n",
       "114             0                                0                    0   \n",
       "438             0                                0                    0   \n",
       "732             0                                0                    0   \n",
       "540             0                                0                    0   \n",
       "\n",
       "     Walk_and_footsteps  Water_tap_and_faucet  Waves_and_surf  Whispering  \\\n",
       "581                   0                     0               0           0   \n",
       "114                   0                     0               0           0   \n",
       "438                   0                     0               0           0   \n",
       "732                   0                     0               0           0   \n",
       "540                   0                     0               0           0   \n",
       "\n",
       "     Writing  Yell  Zipper_(clothing)  \n",
       "581        0     0                  0  \n",
       "114        0     0                  0  \n",
       "438        0     0                  0  \n",
       "732        0     0                  0  \n",
       "540        0     0                  0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples= 19815   Number of classes= 1168\n",
      "Number of test examples= 1120   Number of classes= 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train examples=\", train.shape[0], \"  Number of classes=\", len(set(train['labels'])))\n",
    "print(\"Number of test examples=\", test.shape[0], \"  Number of classes=\", len(set(test.columns[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- note that due to multi-labeld records in train, the number of unique classes is 213 (which is more than the test set's 80)\n",
    "- For simplicity, we will exclude multi-labeled records in train, so the number of unique label is 74 ( < 80 ).\n",
    "When buliding a valid model, we must consider this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16566\n"
     ]
    }
   ],
   "source": [
    "train = train[train['labels'].isin(test.columns[1:])]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14104627766599598"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4970 - 4269) / 4970 # # We lose roughly 14% of our data set in order to make this simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "category_group = train.groupby(['labels']).count()\n",
    "category_group.columns = ['counts']\n",
    "print(len(category_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Writing</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tap</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bark</th>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  counts\n",
       "labels                                  \n",
       "Writing                              175\n",
       "Tap                                  248\n",
       "Male_speech_and_man_speaking         263\n",
       "Female_speech_and_woman_speaking     266\n",
       "Bark                                 257"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_group.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bit-depth = 16: The amplitude of each sample in the audio is one of 2^16 (=65536) possible values.\n",
    "- Samplig rate = 44.1 kHz: Each second in the audio consists of 44100 samples. So, if the duration of the audio file is 3.2 seconds, the audio will consist of 44100*3.2 = 141120 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['nframes'] = train['fname'].apply(lambda f: wave.open(data_path + '/train_noisy/' + f).getnframes())\n",
    "test['nframes'] = test['fname'].apply(lambda f: wave.open(data_path + '/test/' + f).getnframes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>nframes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17721</th>\n",
       "      <td>e48807e5.wav</td>\n",
       "      <td>Bass_drum</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>6a35aa6f.wav</td>\n",
       "      <td>Skateboard</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11393</th>\n",
       "      <td>92dc74c3.wav</td>\n",
       "      <td>Crowd</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12373</th>\n",
       "      <td>9ede9f1b.wav</td>\n",
       "      <td>Gong</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>1adc2c14.wav</td>\n",
       "      <td>Race_car_and_auto_racing</td>\n",
       "      <td>354304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname                    labels  nframes\n",
       "17721  e48807e5.wav                 Bass_drum   661500\n",
       "8255   6a35aa6f.wav                Skateboard   661500\n",
       "11393  92dc74c3.wav                     Crowd   661500\n",
       "12373  9ede9f1b.wav                      Gong   661500\n",
       "2080   1adc2c14.wav  Race_car_and_auto_racing   354304"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model using Raw Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, GlobalMaxPool1D, Input, MaxPool1D, concatenate)\n",
    "from keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Configuration object stores those learning parameters that are shared\n",
    "# between data generators models, and training functions. Anything that is\n",
    "# global as far as the training is concerned can become the part of Configuration object.\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000,\n",
    "                 audio_duration=2, \n",
    "                 n_classes=len(category_group),\n",
    "                 use_mfcc=False,\n",
    "                 n_folds=10,\n",
    "                 learning_rate=0.0001, \n",
    "                 max_epochs=50,\n",
    "                 n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.max_epochs = max_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataGenerator class inherits from keras.utils.Sequence .\n",
    "# It is useful for preprocessing and feeding the data to a Keras model.\n",
    "\n",
    "# Note: Sequence are a safer way to do multiprocessing.\n",
    "# This structure guarantees that the network will only train once on each\n",
    "# sample per epoch which is not the case with generators.\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 data_dir,\n",
    "                 list_IDs,\n",
    "                 labels=None, \n",
    "                 batch_size=64,\n",
    "                 preprocessing_fn=lambda x: x):\n",
    "        self.config = config\n",
    "        self.data_dir = data_dir\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.on_epoch_end()\n",
    "        self.dim = self.config.dim\n",
    "\n",
    "    def __len__(self):\n",
    "        # Once initialized with a batch_size, DataGenerator computes the number of batches in an epoch.\n",
    "        # The __len__ method tells Keras how many batches to draw in each epoch.\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # The __getitem__ method takes an index (which is the batch number) and\n",
    "        # returns a batch of the data (both X and y) after calculating the offset.\n",
    "        # During test time, only X is returned.\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # If we want to perform some action after each epoch (like shuffle the data,\n",
    "        # or increase the proportion of augmented data), we can use the on_epoch_end method.\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        cur_batch_size = len(list_IDs_temp)\n",
    "        X = np.empty((cur_batch_size, *self.dim))\n",
    "\n",
    "        input_length = self.config.audio_length\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            file_path = self.data_dir + ID\n",
    "            \n",
    "            # Read and Resample the audio\n",
    "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate, res_type='kaiser_fast')\n",
    "\n",
    "            # Random offset / Padding\n",
    "            if len(data) > input_length:\n",
    "                max_offset = len(data) - input_length\n",
    "                offset = np.random.randint(max_offset)\n",
    "                data = data[offset:(input_length+offset)]\n",
    "            else:\n",
    "                if input_length > len(data):\n",
    "                    max_offset = input_length - len(data)\n",
    "                    offset = np.random.randint(max_offset)\n",
    "                else:\n",
    "                    offset = 0\n",
    "                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "                \n",
    "            # Normalization + Other Preprocessing\n",
    "            if self.config.use_mfcc:\n",
    "                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate, n_mfcc=self.config.n_mfcc)\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "            else:\n",
    "                data = self.preprocessing_fn(data)[:, np.newaxis]\n",
    "            X[i,] = data\n",
    "\n",
    "        if self.labels is not None:\n",
    "            y = np.empty(cur_batch_size, dtype=int)\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                y[i] = self.labels[ID]\n",
    "            return X, to_categorical(y, num_classes=self.config.n_classes)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization is a crucial preprocessing step.\n",
    "# The simplest method is rescaling the range of features to scale the range in [0, 1].\n",
    "\n",
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dummy model is just for debugging purpose.\n",
    "\n",
    "def get_1d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = GlobalMaxPool1D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our 1D Conv model is fairly deep and is trained\n",
    "# using Adam Optimizer with a learning rate of 0.0001\n",
    "\n",
    "def get_1d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=relu)(x)\n",
    "    x = Dense(1028, activation=relu)(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>nframes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00097e21.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000b6cfb.wav</td>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0019adae.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001b819d.wav</td>\n",
       "      <td>Bass_guitar</td>\n",
       "      <td>661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0020becb.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "      <td>687104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                        labels  nframes\n",
       "0  00097e21.wav  Bathtub_(filling_or_washing)   661500\n",
       "1  000b6cfb.wav                    Motorcycle   661500\n",
       "4  0019adae.wav                      Raindrop   661500\n",
       "5  001b819d.wav                   Bass_guitar   661500\n",
       "9  0020becb.wav                     Harmonica   687104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is important to convert raw labels to integer indices\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(train['labels'].unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "\n",
    "train[\"label_idx\"] = train['labels'].apply(lambda x: label_idx[x])\n",
    "\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>nframes</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00097e21.wav</th>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "      <td>661500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b6cfb.wav</th>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>661500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019adae.wav</th>\n",
       "      <td>Raindrop</td>\n",
       "      <td>661500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001b819d.wav</th>\n",
       "      <td>Bass_guitar</td>\n",
       "      <td>661500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020becb.wav</th>\n",
       "      <td>Harmonica</td>\n",
       "      <td>687104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    labels  nframes  label_idx\n",
       "fname                                                         \n",
       "00097e21.wav  Bathtub_(filling_or_washing)   661500          0\n",
       "000b6cfb.wav                    Motorcycle   661500          1\n",
       "0019adae.wav                      Raindrop   661500          2\n",
       "001b819d.wav                   Bass_guitar   661500          3\n",
       "0020becb.wav                     Harmonica   687104          4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw labels with integer indices\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=16000, audio_duration=2, n_folds=10, learning_rate=0.001)\n",
    "\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=100, audio_duration=1, n_folds=2, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold:  0\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "220/233 [===========================>..] - ETA: 2:12 - loss: 4.2919 - acc: 0.0228"
     ]
    }
   ],
   "source": [
    "PREDICTION_FOLDER = \"predictions_1d_conv\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "# We use from sklearn.model_selection.StratifiedKFold for splitting the trainig data into 10 folds.\n",
    "skf = StratifiedKFold(n_splits=config.n_folds)\n",
    "\n",
    "for i, (train_split, val_split) in enumerate(skf.split(train.index, train.label_idx)):\n",
    "    train_set = train.iloc[train_split]\n",
    "    val_set = train.iloc[val_split]\n",
    "    \n",
    "    # We use some Keras callbacks to monitor the training.\n",
    "    # ModelCheckpoint saves the best weight of our model (using validation data).\n",
    "    # We use this weight to make test predictions.\n",
    "    checkpoint = ModelCheckpoint('best_noisy_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    # EarlyStopping stops the training once validation loss ceases to decrease\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    # TensorBoard helps us visualize training and validation loss and accuracy.\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%d'%i, write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"\\nFold: \", i)\n",
    "    if COMPLETE_RUN:\n",
    "        model = get_1d_conv_model(config)\n",
    "    else:\n",
    "        model = get_1d_dummy_model(config)\n",
    "\n",
    "    # We fit the model using DataGenerator for training and validation splits.\n",
    "    train_generator = DataGenerator(config, data_path + '/train_noisy/', train_set.index, \n",
    "                                    train_set.label_idx, batch_size=64,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    val_generator = DataGenerator(config, data_path + '/train_noisy/', val_set.index, \n",
    "                                  val_set.label_idx, batch_size=64,\n",
    "                                  preprocessing_fn=audio_norm)\n",
    "    \n",
    "    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n",
    "                                  epochs=config.max_epochs, use_multiprocessing=True, max_queue_size=20)\n",
    "    \n",
    "#     model.load_weights('../working/best_%d.h5'%i)\n",
    "    \n",
    "    # Save train predictions\n",
    "    train_generator = DataGenerator(config, data_path + '/train_noisy/', train.index, batch_size=128,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n",
    "                                          max_queue_size=20, verbose=1)\n",
    "    \n",
    "    # We get both training and test predictions and save them as .npy format.\n",
    "    # We also generate a submission file. For 10-fold CV, the number of prediction files should be 10.\n",
    "    # We will ensemble these predictions later.\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "    \n",
    "    # Save test predictions\n",
    "    test_generator = DataGenerator(config, data_path + '/test/', test.index, batch_size=128,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n",
    "                                          max_queue_size=20, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "    \n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions are saved as following.\n",
    "os.listdir('./predictions_1d_conv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembling 1D Conv Predictions\n",
    "# Now that we have trained our model, it is time average the predictions of X-folds.\n",
    "# We will try Geometric Mean averaging.\n",
    "\n",
    "pred_list = []\n",
    "for i in range(config.n_folds):\n",
    "    pred_list.append(np.load(\"./predictions_1d_conv/noisy_test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "\n",
    "# calculate geometric mean\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv(data_path + '/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"1d_conv_noisy_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
