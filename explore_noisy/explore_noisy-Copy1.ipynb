{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import losses, models, optimizers\n",
    "from keras.layers import (Input, Dense, Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, GlobalMaxPool2D, MaxPool2D, concatenate, Activation)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras import backend as K\n",
    "from keras.callbacks import (EarlyStopping, ModelCheckpoint, TensorBoard)\n",
    "from keras.activations import relu, softmax\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "                                                                                                                                                                                                                                                                                                            import librosa\n",
    "                                                                                                                                                                                                                                                                                                            import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to True for full dataset and learning\n",
    "COMPLETE_RUN = False\n",
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + \"/train_curated.csv\")\n",
    "test = pd.read_csv(data_path + \"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples= 4970   Number of classes= 213\n",
      "Number of test examples= 1120   Number of classes= 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train examples=\", train.shape[0], \"  Number of classes=\", len(set(train['labels'])))\n",
    "print(\"Number of test examples=\", test.shape[0], \"  Number of classes=\", len(set(test.columns[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train['labels'])) # But now we're working with less than 7% of the original number of labels that describes more 83% of all the clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4269\n"
     ]
    }
   ],
   "source": [
    "# Same as with the curated set, we'll ignore multi labeled rows for now.\n",
    "# Unlike the curated set though this will drastically cut down a large portion of the data set\n",
    "train = train[train['labels'].isin(test.columns[1:])]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "category_group = train.groupby(['labels']).count()\n",
    "category_group.columns = ['counts']\n",
    "print(len(category_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Configuration object stores those learning parameters that are shared\n",
    "# between data generators models, and training functions. Anything that is\n",
    "# global as far as the training is concerned can become the part of Configuration object.\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000,\n",
    "                 audio_duration=2, \n",
    "                 n_classes=len(category_group),\n",
    "                 use_mfcc=False,\n",
    "                 n_folds=10,\n",
    "                 learning_rate=0.0001, \n",
    "                 max_epochs=50,\n",
    "                 n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    \n",
    "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
    "    x = GlobalMaxPool2D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_2d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    \n",
    "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname labels\n",
       "0  0006ae4e.wav   Bark"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is important to convert raw labels to integer indices\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(train['labels'].unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "\n",
    "train[\"label_idx\"] = train['labels'].apply(lambda x: label_idx[x])\n",
    "\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0006ae4e.wav</th>\n",
       "      <td>Bark</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             labels  label_idx\n",
       "fname                         \n",
       "0006ae4e.wav   Bark          0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw labels with integer indices\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=44100, audio_duration=2, n_folds=10, \n",
    "                learning_rate=0.001, use_mfcc=True, n_mfcc=40)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=44100, audio_duration=2, n_folds=2, \n",
    "                    max_epochs=1, use_mfcc=True, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, config, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0], config.dim[0], config.dim[1], 1))\n",
    "    input_length = config.audio_length\n",
    "    for i, fname in enumerate(df.index):\n",
    "        file_path = data_dir + fname\n",
    "        data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "        data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        X[i,] = data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = librosa.core.load( data_path + '/train_curated/0006ae4e.wav', sr=config.sampling_rate, res_type=\"kaiser_fast\")\n",
    "data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 607)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 173, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "X_train = prepare_data(train, config, data_path + '/train_curated/')\n",
    "X_test = prepare_data(test, config, data_path + '/test/')\n",
    "y_train = to_categorical(train.label_idx.astype('str'), num_classes=config.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fname\n",
       "0006ae4e.wav     0\n",
       "0019ef41.wav     1\n",
       "001ec0ad.wav     2\n",
       "0026c7cb.wav     3\n",
       "0026f116.wav     2\n",
       "003be5db.wav     4\n",
       "004ca909.wav     5\n",
       "00713ec2.wav     6\n",
       "00975c2a.wav     7\n",
       "009ca29f.wav     8\n",
       "00b0b76f.wav     9\n",
       "00c17dd2.wav    10\n",
       "00c40a6d.wav    11\n",
       "00c4e82c.wav    12\n",
       "00c7ff40.wav    13\n",
       "00c91dfc.wav     8\n",
       "00ffa0d2.wav     5\n",
       "0110ba24.wav    14\n",
       "012c15b5.wav    15\n",
       "013b01b9.wav    16\n",
       "01565c33.wav    17\n",
       "015a50b9.wav     0\n",
       "0164cba5.wav    18\n",
       "0175a379.wav    19\n",
       "019234bc.wav    20\n",
       "0199c0a0.wav    21\n",
       "02171503.wav    22\n",
       "0217540b.wav    23\n",
       "02286d70.wav    24\n",
       "02356bfd.wav     3\n",
       "                ..\n",
       "7533287e.wav    37\n",
       "754307e6.wav     5\n",
       "7554eee4.wav     5\n",
       "75ba74db.wav    30\n",
       "75c81fe6.wav    13\n",
       "75e092b5.wav    25\n",
       "763d2655.wav    29\n",
       "764b5c87.wav    19\n",
       "7654ee3e.wav    66\n",
       "766e8319.wav     8\n",
       "766f150f.wav    28\n",
       "76795e3e.wav    48\n",
       "76841420.wav     4\n",
       "76a91e03.wav    33\n",
       "76ad78c3.wav    52\n",
       "76b73017.wav    17\n",
       "76bf1389.wav    52\n",
       "76cb5441.wav    18\n",
       "76d21a78.wav    17\n",
       "76d32c4a.wav    51\n",
       "76daf232.wav    46\n",
       "76f87729.wav    32\n",
       "771343bb.wav    68\n",
       "771f6c75.wav    18\n",
       "7720cc18.wav    38\n",
       "772e59c8.wav    17\n",
       "7730996a.wav    20\n",
       "774e2072.wav    66\n",
       "7752cc8a.wav    38\n",
       "775336b3.wav    48\n",
       "Name: label_idx, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 40, 173, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 40, 173, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 80)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Fold:  0\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 981 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "981/981 [==============================] - 37s 38ms/step - loss: 4.5947 - acc: 0.0153 - val_loss: 4.6229 - val_acc: 0.0079\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.62285, saving model to best_0.h5\n",
      "2000/2000 [==============================] - 15s 7ms/step\n",
      "1120/1120 [==============================] - 8s 7ms/step\n",
      "##################################################\n",
      "Fold:  1\n",
      "Train on 1019 samples, validate on 981 samples\n",
      "Epoch 1/1\n",
      "1019/1019 [==============================] - 35s 34ms/step - loss: 4.5682 - acc: 0.0177 - val_loss: 4.6242 - val_acc: 0.0122\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.62418, saving model to best_1.h5\n",
      "2000/2000 [==============================] - 15s 7ms/step\n",
      "1120/1120 [==============================] - 8s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training 2D Conv on MFCC\n",
    "\n",
    "PREDICTION_FOLDER = \"predictions_2d_conv\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=config.n_folds)\n",
    "\n",
    "for i, (train_split, val_split) in enumerate(skf.split(train.index, train.label_idx)):\n",
    "    K.clear_session()\n",
    "    X, y, X_val, y_val = X_train[train_split], y_train[train_split], X_train[val_split], y_train[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%i'%i, write_graph=True)\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"#\"*50)\n",
    "    print(\"Fold: \", i)\n",
    "    model = get_2d_conv_model(config)\n",
    "    history = model.fit(X, y, validation_data=(X_val, y_val), callbacks=callbacks_list, \n",
    "                        batch_size=64, epochs=config.max_epochs)\n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "    # Save train predictions\n",
    "    predictions = model.predict(X_train, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Save test predictions\n",
    "    predictions = model.predict(X_test, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembling 2D Conv Predictions¶\n",
    "\n",
    "# pred_list = []\n",
    "# for i in range(config.n_folds):\n",
    "#     pred_list.append(np.load(\"./predictions_2d_conv/test_predictions_%d.npy\"%i))\n",
    "# prediction = np.ones_like(pred_list[0])\n",
    "# for pred in pred_list:\n",
    "#     prediction = prediction*pred\n",
    "# prediction = prediction**(1./len(pred_list))\n",
    "# # Make a submission file\n",
    "# top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "# predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "# test = pd.read_csv(data_path + '/sample_submission.csv')\n",
    "# test['label'] = predicted_labels\n",
    "# test[['fname', 'label']].to_csv(\"2d_conv_ensembled_curated_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
